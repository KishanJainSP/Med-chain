"""
Test Ollama integration with chat endpoint
"""
import sys
import requests
import json

BASE_URL = "http://localhost:8000/api"

def test_health_check():
    """Test if Ollama is available"""
    print("=" * 60)
    print("Testing Health Check")
    print("=" * 60)
    
    try:
        response = requests.get(f"{BASE_URL}/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            ollama_available = data.get("ai_models", {}).get("ollama_available", False)
            
            print(f"\n✓ Server is healthy")
            print(f"  Ollama available: {ollama_available}")
            
            if ollama_available:
                print("\n✓ Ollama is ready for chat!")
                return True
            else:
                print("\n⚠ Ollama is not available")
                print("  Chat will use fallback AI")
                return False
        else:
            print(f"\n✗ Server returned status: {response.status_code}")
            return False
    except Exception as e:
        print(f"\n✗ Error: {e}")
        print("\nIs the server running?")
        print("  Run: python backend/start_server.py")
        return False

def test_chat_message(user_id="test_patient_123"):
    """Test sending a chat message"""
    print("\n" + "=" * 60)
    print("Testing Chat Message")
    print("=" * 60)
    
    test_message = "What is diabetes and how can I manage it?"
    
    print(f"\nSending message: '{test_message}'")
    
    try:
        response = requests.post(
            f"{BASE_URL}/chat",
            json={
                "message": test_message,
                "attached_record_ids": [],
                "user_id": user_id,
                "user_role": "patient"
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            
            print("\n✓ Chat response received!")
            print(f"\n{'='*60}")
            print("Response:")
            print(f"{'='*60}")
            print(data.get("response", "No response"))
            print(f"{'='*60}")
            
            ollama_powered = data.get("ollama_powered", False)
            print(f"\nOllama powered: {ollama_powered}")
            
            if ollama_powered:
                print("✓ Response generated by Ollama AI")
            else:
                print("⚠ Response generated by fallback AI")
            
            return True
        else:
            print(f"\n✗ Server returned status: {response.status_code}")
            print(f"  Response: {response.text}")
            return False
            
    except requests.exceptions.Timeout:
        print("\n✗ Request timed out")
        print("  Ollama might be processing slowly")
        print("  Try a simpler question or wait longer")
        return False
    except Exception as e:
        print(f"\n✗ Error: {e}")
        return False

def test_chat_with_context():
    """Test chat with medical context"""
    print("\n" + "=" * 60)
    print("Testing Chat with Medical Context")
    print("=" * 60)
    
    test_message = "I have chest pain and shortness of breath. Should I be worried?"
    
    print(f"\nSending message: '{test_message}'")
    
    try:
        response = requests.post(
            f"{BASE_URL}/chat",
            json={
                "message": test_message,
                "attached_record_ids": [],
                "user_id": "test_patient_123",
                "user_role": "patient"
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            
            print("\n✓ Chat response received!")
            print(f"\n{'='*60}")
            print("Response:")
            print(f"{'='*60}")
            response_text = data.get("response", "No response")
            # Print first 500 chars
            print(response_text[:500] + ("..." if len(response_text) > 500 else ""))
            print(f"{'='*60}")
            
            ollama_powered = data.get("ollama_powered", False)
            
            if ollama_powered:
                print("\n✓ Ollama provided contextual medical advice")
            else:
                print("\n⚠ Fallback AI provided response")
            
            return True
        else:
            print(f"\n✗ Server returned status: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"\n✗ Error: {e}")
        return False

def test_chat_history(user_id="test_patient_123"):
    """Test retrieving chat history"""
    print("\n" + "=" * 60)
    print("Testing Chat History")
    print("=" * 60)
    
    try:
        response = requests.get(
            f"{BASE_URL}/chat/history",
            params={"user_id": user_id, "limit": 5},
            timeout=10
        )
        
        if response.status_code == 200:
            history = response.json()
            
            print(f"\n✓ Retrieved {len(history)} message(s)")
            
            if history:
                print("\nRecent messages:")
                for i, msg in enumerate(history[-3:], 1):
                    print(f"\n  {i}. User: {msg.get('message', '')[:50]}...")
                    print(f"     Bot: {msg.get('response', '')[:50]}...")
            else:
                print("\n  No chat history yet")
            
            return True
        else:
            print(f"\n✗ Server returned status: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"\n✗ Error: {e}")
        return False

def main():
    print("\n" + "=" * 60)
    print("MedChain Chat + Ollama Integration Test")
    print("=" * 60)
    
    # Test 1: Health check
    ollama_available = test_health_check()
    
    if not ollama_available:
        print("\n⚠ Warning: Ollama is not available")
        print("  Chat will still work but use fallback AI")
        print("\nTo enable Ollama:")
        print("  1. Run: python backend/check_ollama.py")
        print("  2. If needed: python backend/install_ollama_model.py")
    
    # Test 2: Simple chat message
    test_chat_message()
    
    # Test 3: Chat with medical context
    test_chat_with_context()
    
    # Test 4: Chat history
    test_chat_history()
    
    # Summary
    print("\n" + "=" * 60)
    print("Test Summary")
    print("=" * 60)
    
    if ollama_available:
        print("\n✓ SUCCESS! Chat is powered by Ollama AI")
        print("\nYou can now:")
        print("  1. Open your MedChain UI")
        print("  2. Click 'AI Assistant' button")
        print("  3. Chat with Ollama-powered medical AI")
        print("  4. Get natural language responses")
    else:
        print("\n⚠ Chat is working but Ollama is not available")
        print("\nTo enable Ollama:")
        print("  1. Check status: python backend/check_ollama.py")
        print("  2. Install model: python backend/install_ollama_model.py")
        print("  3. Restart server: python backend/start_server.py")

if __name__ == "__main__":
    main()
